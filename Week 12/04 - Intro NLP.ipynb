{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro NLP\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/768/1*JbQ58utmVAnAQ1G7ueLMAA.png\">\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "\n",
    "**N**atural **L**anguage **P**rocessing\n",
    "\n",
    "It is a field that combines computer science, linguistics and programming languages, to understand how interactions between humans and machines can be created through natural language, which is what we humans use to communicate.\n",
    "\n",
    "\n",
    "**N**atural **L**anguage **U**nderstanding (NLU)\n",
    "\n",
    "It is a smaller field which is in charge of specific tasks that the machines can execute in the process of communication with human beings so that those tasks reflect that the robot is capable of processing our language and understanding it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do we find it?\n",
    "\n",
    "- Search machines\n",
    "    <img width=300 src=\"https://www.reliablesoft.net/wp-content/uploads/2016/12/best-search-engines.png\">\n",
    "- Text translation\n",
    "    <img width=300 src=\"https://www.at-languagesolutions.com/en/wp-content/uploads/2018/02/translate.jpg\">\n",
    "- Chatbots\n",
    "    <img width=300 src=\"https://www.grupoftp.com/noticias/wp-content/uploads/2018/03/Chatbot11-825x510.jpg\">\n",
    "- Discourse analysis\n",
    "    <img width=300 src=\"https://307853.smushcdn.com/956669/wp-content/uploads/sites/53/2018/06/Bea3.jpg?lossy=1&strip=1&webp=1\">\n",
    "- Speech recognition\n",
    "    <img width=300 src=\"https://i0.wp.com/ventsmagazine.com/wp-content/uploads/2019/11/1NhOH4X9wKWfO6o8faYFf-w.png?fit=556%2C260&ssl=1\">\n",
    "- etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is so hard?\n",
    "\n",
    "### How can we interpt this poem:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/640/1*oUFe82URjWheBW7Ch0dVGw.jpeg\">\n",
    "\n",
    "\n",
    "**human language is fuzzy, ambiguous and requires a lot of context.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/trf-ai20180307-180306132755/95/shaping-our-ai-strategy-7-638.jpg?cb=1520342960\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "- input text -> Normalization\n",
    "- Normalization:\n",
    "    - Tokenization\n",
    "    <img width=400 src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-50-56.png\">\n",
    "    - Stemming\n",
    "    <img width=400 src=\"https://qph.fs.quoracdn.net/main-qimg-cd7f4bafaa42639deb999b1580bea69f\">\n",
    "    - Segmentation\n",
    "    <img src=\"https://s3.amazonaws.com/work-sample-images/blog_segmentation.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus\n",
    "\n",
    "Corpus is a set of texts\n",
    "\n",
    "<img src=\"http://corpora.lancs.ac.uk/clmtp/images/2-tagconc.jpg\">\n",
    "\n",
    "### Corpora \n",
    "\n",
    "Corpora is a set of multiple corpus \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to\n",
      "[nltk_data]     C:\\Users\\TheGlitchCat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "# Download dataset\n",
    "nltk.download('cess_esp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['El', 'grupo', 'estatal', 'Electricité_de_France', '-Fpa-', 'EDF', '-Fpt-', 'anunció', 'hoy', ',', 'jueves', ',', 'la', 'compra', 'del', '51_por_ciento', 'de', 'la', 'empresa', 'mexicana', 'Electricidad_Águila_de_Altamira', '-Fpa-', 'EAA', '-Fpt-', ',', 'creada', 'por', 'el', 'japonés', 'Mitsubishi_Corporation', 'para', 'poner_en_marcha', 'una', 'central', 'de', 'gas', 'de', '495', 'megavatios', '.'], ['Una', 'portavoz', 'de', 'EDF', 'explicó', 'a', 'EFE', 'que', 'el', 'proyecto', 'para', 'la', 'construcción', 'de', 'Altamira_2', ',', 'al', 'norte', 'de', 'Tampico', ',', 'prevé', 'la', 'utilización', 'de', 'gas', 'natural', 'como', 'combustible', 'principal', 'en', 'una', 'central', 'de', 'ciclo', 'combinado', 'que', 'debe', 'empezar', 'a', 'funcionar', 'en', 'mayo_del_2002', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "# Regular expressions \n",
    "import re\n",
    "\n",
    "corpus = nltk.corpus.cess_esp.sents()\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6030\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192685\n",
      "['El', 'grupo', 'estatal', 'Electricité_de_France', '-Fpa-', 'EDF', '-Fpt-', 'anunció', 'hoy', ',', 'jueves', ',', 'la', 'compra', 'del', '51_por_ciento', 'de', 'la', 'empresa', 'mexicana', 'Electricidad_Águila_de_Altamira', '-Fpa-', 'EAA', '-Fpt-', ',', 'creada', 'por', 'el', 'japonés', 'Mitsubishi_Corporation']\n"
     ]
    }
   ],
   "source": [
    "# only one list \n",
    "\n",
    "flatten = [w for l in corpus for w in l]\n",
    "print(len(flatten))\n",
    "print(flatten[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estatal', 'jueves', 'empresa', 'centrales', 'francesa']\n"
     ]
    }
   ],
   "source": [
    "# p = pattern\n",
    "# s = string\n",
    "# re.search(p,s) -> return true or false \n",
    "\n",
    "arr = [w for w in flatten if re.search('es', w)]\n",
    "print(arr[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jueves', 'centrales', 'millones', 'millones', 'dólares']\n"
     ]
    }
   ],
   "source": [
    "# $ -> ends with \n",
    "arr = [w for w in flatten if re.search('es$', w)]\n",
    "print(arr[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estatal', 'es', 'esta', 'esta', 'eso']\n"
     ]
    }
   ],
   "source": [
    "# ^ -> start with \n",
    "arr = [w for w in flatten if re.search('^es', w)]\n",
    "print(arr[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grupo', 'hoy', 'gas', 'gas', 'intervendrá']\n"
     ]
    }
   ],
   "source": [
    "# range = [a-z] [abc] \n",
    " \n",
    "arr = [w for w in flatten if re.search('^[ghi]', w)]\n",
    "print(arr[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['El', 'grupo', 'estatal', 'Electricité_de_France', '-Fpa-']\n",
      "['norte', 'no', 'no', 'noche', 'no']\n"
     ]
    }
   ],
   "source": [
    "# Clausure\n",
    "# * = repeat 0 or more \n",
    "# + = repeat 1 or more \n",
    "\n",
    "arr = [w for w in flatten if re.search('^(no)*', w)]\n",
    "print(arr[:5])\n",
    "\n",
    "arr = [w for w in flatten if re.search('^(no)+', w)]\n",
    "print(arr[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is \n",
      " no raw text\n",
      "this is \\n no raw text\n"
     ]
    }
   ],
   "source": [
    "print('this is \\n no raw text')\n",
    "\n",
    "# raw\n",
    "print(r'this is \\n no raw text')\n",
    "\n",
    "# Raw\n",
    "text = \"\"\" Cuando sea el rey del mundo (imaginaba él en su cabeza) no tendré que  preocuparme por estas bobadas. \n",
    "           Era solo un niño de 7 años, pero pensaba que podría ser cualquier cosa que su imaginación le permitiera \n",
    "           visualizar en su cabeza ...\"\"\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Cuando', 'sea', 'el', 'rey', 'del', 'mundo', '(imaginaba', 'él', 'en', 'su', 'cabeza)', 'no', 'tendré', 'que', '', 'preocuparme', 'por', 'estas', 'bobadas.', '\\n', '', '', '', '', '', '', '', '', '', '', 'Era', 'solo', 'un', 'niño', 'de', '7', 'años,', 'pero', 'pensaba', 'que', 'podría', 'ser', 'cualquier', 'cosa', 'que', 'su', 'imaginación', 'le', 'permitiera', '\\n', '', '', '', '', '', '', '', '', '', '', 'visualizar', 'en', 'su', 'cabeza', '...']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization with spaces \n",
    "spaces = re.split(r' ', text)\n",
    "\n",
    "print(spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Cuando', 'sea', 'el', 'rey', 'del', 'mundo', '(imaginaba', 'él', 'en', 'su', 'cabeza)', 'no', 'tendré', 'que', 'preocuparme', 'por', 'estas', 'bobadas.', 'Era', 'solo', 'un', 'niño', 'de', '7', 'años,', 'pero', 'pensaba', 'que', 'podría', 'ser', 'cualquier', 'cosa', 'que', 'su', 'imaginación', 'le', 'permitiera', 'visualizar', 'en', 'su', 'cabeza', '...']\n"
     ]
    }
   ],
   "source": [
    "# Regex Tokenization\n",
    "reg = re.split(r'[ \\t\\n]+', text)\n",
    "print(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Cuando', 'sea', 'el', 'rey', 'del', 'mundo', 'imaginaba', 'él', 'en', 'su', 'cabeza', 'no', 'tendré', 'que', 'preocuparme', 'por', 'estas', 'bobadas', 'Era', 'solo', 'un', 'niño', 'de', '7', 'años', 'pero', 'pensaba', 'que', 'podría', 'ser', 'cualquier', 'cosa', 'que', 'su', 'imaginación', 'le', 'permitiera', 'visualizar', 'en', 'su', 'cabeza', '']\n"
     ]
    }
   ],
   "source": [
    "# Special Regex Tokenization\n",
    "reg = re.split(r'[ \\W\\t\\n]+', text)\n",
    "print(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Tokenization\n",
    "\n",
    "corrupt_text = 'En U.S.A. esa consola portatil vale $399.99 ... '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'''(?x)                  # Flag for verbose mode\n",
    "              (?:[A-Z]\\.)+          # Matches with abbreviations like U.S.A.\n",
    "              | \\w+(?:-\\w+)*        # Matches words that may have an internal hyphen\n",
    "              | \\$?\\d+(?:\\.\\d+)?%?  # Matches money or percentages like $ 15.5 or 100%\n",
    "              | \\.\\.\\.              # Matches ellipsis\n",
    "              | [][.,;\"'?():-_`]    # Matches punctuation marks\n",
    "              '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['En', 'U.S.A.', 'esa', 'consola', 'portatil', 'vale', '$399.99', '...']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.regexp_tokenize(corrupt_text, pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cuando',\n",
       " 'sea',\n",
       " 'el',\n",
       " 'rey',\n",
       " 'del',\n",
       " 'mundo',\n",
       " '(',\n",
       " 'imaginaba',\n",
       " 'él',\n",
       " 'en',\n",
       " 'su',\n",
       " 'cabeza',\n",
       " ')',\n",
       " 'no',\n",
       " 'tendré',\n",
       " 'que',\n",
       " 'preocuparme',\n",
       " 'por',\n",
       " 'estas',\n",
       " 'bobadas',\n",
       " '.',\n",
       " 'Era',\n",
       " 'solo',\n",
       " 'un',\n",
       " 'niño',\n",
       " 'de',\n",
       " '7',\n",
       " 'años',\n",
       " ',',\n",
       " 'pero',\n",
       " 'pensaba',\n",
       " 'que',\n",
       " 'podría',\n",
       " 'ser',\n",
       " 'cualquier',\n",
       " 'cosa',\n",
       " 'que',\n",
       " 'su',\n",
       " 'imaginación',\n",
       " 'le',\n",
       " 'permitiera',\n",
       " 'visualizar',\n",
       " 'en',\n",
       " 'su',\n",
       " 'cabeza',\n",
       " '...']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.regexp_tokenize(text, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_news_text = '''\n",
    "    The pound has risen 0.35% against the dollar to $1.3067 after the Bank of England's Monetary Policy Committee voted to hold the interest rate.\n",
    "\n",
    "    Sterling also gained against the euro, up 0.21% at €1.1849.\n",
    "\n",
    "    The MPC made clear, however, that it may act if the UK economy fails to gain momentum.\n",
    "\n",
    "    \"With Mark Carney seemingly having deferred this policy decision to his successor, Andrew Bailey will need to land on his feet running,\" says Principal Global Investors' market strategist, Seema Shah.\n",
    "\n",
    "    \"Unless economic activity data improves measurably over the coming months, reflecting proof of the so-called 'Boris bounce', and interest rate cut is likely to remain on the agenda for 2020.\".\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'pound',\n",
       " 'has',\n",
       " 'risen',\n",
       " '0',\n",
       " '.',\n",
       " '35',\n",
       " 'against',\n",
       " 'the',\n",
       " 'dollar',\n",
       " 'to',\n",
       " '$1.3067',\n",
       " 'after',\n",
       " 'the',\n",
       " 'Bank',\n",
       " 'of',\n",
       " 'England',\n",
       " \"'\",\n",
       " 's',\n",
       " 'Monetary',\n",
       " 'Policy',\n",
       " 'Committee',\n",
       " 'voted',\n",
       " 'to',\n",
       " 'hold',\n",
       " 'the',\n",
       " 'interest',\n",
       " 'rate',\n",
       " '.',\n",
       " 'Sterling',\n",
       " 'also',\n",
       " 'gained',\n",
       " 'against',\n",
       " 'the',\n",
       " 'euro',\n",
       " ',',\n",
       " 'up',\n",
       " '0',\n",
       " '.',\n",
       " '21',\n",
       " 'at',\n",
       " '1',\n",
       " '.',\n",
       " '1849',\n",
       " '.',\n",
       " 'The',\n",
       " 'MPC',\n",
       " 'made',\n",
       " 'clear',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'that',\n",
       " 'it',\n",
       " 'may',\n",
       " 'act',\n",
       " 'if',\n",
       " 'the',\n",
       " 'UK',\n",
       " 'economy',\n",
       " 'fails',\n",
       " 'to',\n",
       " 'gain',\n",
       " 'momentum',\n",
       " '.',\n",
       " '\"',\n",
       " 'With',\n",
       " 'Mark',\n",
       " 'Carney',\n",
       " 'seemingly',\n",
       " 'having',\n",
       " 'deferred',\n",
       " 'this',\n",
       " 'policy',\n",
       " 'decision',\n",
       " 'to',\n",
       " 'his',\n",
       " 'successor',\n",
       " ',',\n",
       " 'Andrew',\n",
       " 'Bailey',\n",
       " 'will',\n",
       " 'need',\n",
       " 'to',\n",
       " 'land',\n",
       " 'on',\n",
       " 'his',\n",
       " 'feet',\n",
       " 'running',\n",
       " ',',\n",
       " '\"',\n",
       " 'says',\n",
       " 'Principal',\n",
       " 'Global',\n",
       " 'Investors',\n",
       " \"'\",\n",
       " 'market',\n",
       " 'strategist',\n",
       " ',',\n",
       " 'Seema',\n",
       " 'Shah',\n",
       " '.',\n",
       " '\"',\n",
       " 'Unless',\n",
       " 'economic',\n",
       " 'activity',\n",
       " 'data',\n",
       " 'improves',\n",
       " 'measurably',\n",
       " 'over',\n",
       " 'the',\n",
       " 'coming',\n",
       " 'months',\n",
       " ',',\n",
       " 'reflecting',\n",
       " 'proof',\n",
       " 'of',\n",
       " 'the',\n",
       " 'so-called',\n",
       " \"'\",\n",
       " 'Boris',\n",
       " 'bounce',\n",
       " \"'\",\n",
       " ',',\n",
       " 'and',\n",
       " 'interest',\n",
       " 'rate',\n",
       " 'cut',\n",
       " 'is',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'remain',\n",
       " 'on',\n",
       " 'the',\n",
       " 'agenda',\n",
       " 'for',\n",
       " '2020',\n",
       " '.',\n",
       " '\"',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.regexp_tokenize(bbc_news_text, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_text = '''\n",
    "    El presidente Donald Trump firmó un memorando el 22 de marzo de 2018 bajo el artículo 301 de la Ley de Comercio de 1974, ordenando al Representante Comercial de Estados Unidos (United States Trade Representative, USTR) que se apliquen aranceles de 50 000 millones de dólares a los productos chinos. \n",
    "    En una declaración formal, según establece la ley, Trump dijo que la propuesta de aranceles fue «una respuesta a las prácticas comerciales desleales de China a lo largo de los años», incluyendo el robo de propiedad intelectual.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El',\n",
       " 'presidente',\n",
       " 'Donald',\n",
       " 'Trump',\n",
       " 'firmó',\n",
       " 'un',\n",
       " 'memorando',\n",
       " 'el',\n",
       " '22',\n",
       " 'de',\n",
       " 'marzo',\n",
       " 'de',\n",
       " '2018',\n",
       " 'bajo',\n",
       " 'el',\n",
       " 'artículo',\n",
       " '301',\n",
       " 'de',\n",
       " 'la',\n",
       " 'Ley',\n",
       " 'de',\n",
       " 'Comercio',\n",
       " 'de',\n",
       " '1974',\n",
       " ',',\n",
       " 'ordenando',\n",
       " 'al',\n",
       " 'Representante',\n",
       " 'Comercial',\n",
       " 'de',\n",
       " 'Estados',\n",
       " 'Unidos',\n",
       " '(',\n",
       " 'United',\n",
       " 'States',\n",
       " 'Trade',\n",
       " 'Representative',\n",
       " ',',\n",
       " 'USTR',\n",
       " ')',\n",
       " 'que',\n",
       " 'se',\n",
       " 'apliquen',\n",
       " 'aranceles',\n",
       " 'de',\n",
       " '50',\n",
       " '000',\n",
       " 'millones',\n",
       " 'de',\n",
       " 'dólares',\n",
       " 'a',\n",
       " 'los',\n",
       " 'productos',\n",
       " 'chinos',\n",
       " '.',\n",
       " 'En',\n",
       " 'una',\n",
       " 'declaración',\n",
       " 'formal',\n",
       " ',',\n",
       " 'según',\n",
       " 'establece',\n",
       " 'la',\n",
       " 'ley',\n",
       " ',',\n",
       " 'Trump',\n",
       " 'dijo',\n",
       " 'que',\n",
       " 'la',\n",
       " 'propuesta',\n",
       " 'de',\n",
       " 'aranceles',\n",
       " 'fue',\n",
       " 'una',\n",
       " 'respuesta',\n",
       " 'a',\n",
       " 'las',\n",
       " 'prácticas',\n",
       " 'comerciales',\n",
       " 'desleales',\n",
       " 'de',\n",
       " 'China',\n",
       " 'a',\n",
       " 'lo',\n",
       " 'largo',\n",
       " 'de',\n",
       " 'los',\n",
       " 'años',\n",
       " ',',\n",
       " 'incluyendo',\n",
       " 'el',\n",
       " 'robo',\n",
       " 'de',\n",
       " 'propiedad',\n",
       " 'intelectual',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.regexp_tokenize(wiki_text, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_text2 = '''\n",
    "    El 2 de abril, el Ministerio de Comercio de China impuso aranceles a 128 productos estadounidenses, incluyendo chatarra de aluminio, aviones, automóviles, productos derivados del cerdo y la soja (que tiene un arancel del 25 %), así como a frutas, frutos secos y tuberías de acero (15 %). Al día siguiente, el USTR publicó una lista de más de 1300 categorías de las importaciones chinas, por un valor de 50 000 millones, \n",
    "    a las que se prevé establecer aranceles, incluyendo piezas de aviones, baterías, televisores de pantalla plana, dispositivos médicos, satélites y armas.4​5​6​\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El',\n",
       " '2',\n",
       " 'de',\n",
       " 'abril',\n",
       " ',',\n",
       " 'el',\n",
       " 'Ministerio',\n",
       " 'de',\n",
       " 'Comercio',\n",
       " 'de',\n",
       " 'China',\n",
       " 'impuso',\n",
       " 'aranceles',\n",
       " 'a',\n",
       " '128',\n",
       " 'productos',\n",
       " 'estadounidenses',\n",
       " ',',\n",
       " 'incluyendo',\n",
       " 'chatarra',\n",
       " 'de',\n",
       " 'aluminio',\n",
       " ',',\n",
       " 'aviones',\n",
       " ',',\n",
       " 'automóviles',\n",
       " ',',\n",
       " 'productos',\n",
       " 'derivados',\n",
       " 'del',\n",
       " 'cerdo',\n",
       " 'y',\n",
       " 'la',\n",
       " 'soja',\n",
       " '(',\n",
       " 'que',\n",
       " 'tiene',\n",
       " 'un',\n",
       " 'arancel',\n",
       " 'del',\n",
       " '25',\n",
       " ')',\n",
       " ',',\n",
       " 'así',\n",
       " 'como',\n",
       " 'a',\n",
       " 'frutas',\n",
       " ',',\n",
       " 'frutos',\n",
       " 'secos',\n",
       " 'y',\n",
       " 'tuberías',\n",
       " 'de',\n",
       " 'acero',\n",
       " '(',\n",
       " '15',\n",
       " ')',\n",
       " '.',\n",
       " 'Al',\n",
       " 'día',\n",
       " 'siguiente',\n",
       " ',',\n",
       " 'el',\n",
       " 'USTR',\n",
       " 'publicó',\n",
       " 'una',\n",
       " 'lista',\n",
       " 'de',\n",
       " 'más',\n",
       " 'de',\n",
       " '1300',\n",
       " 'categorías',\n",
       " 'de',\n",
       " 'las',\n",
       " 'importaciones',\n",
       " 'chinas',\n",
       " ',',\n",
       " 'por',\n",
       " 'un',\n",
       " 'valor',\n",
       " 'de',\n",
       " '50',\n",
       " '000',\n",
       " 'millones',\n",
       " ',',\n",
       " 'a',\n",
       " 'las',\n",
       " 'que',\n",
       " 'se',\n",
       " 'prevé',\n",
       " 'establecer',\n",
       " 'aranceles',\n",
       " ',',\n",
       " 'incluyendo',\n",
       " 'piezas',\n",
       " 'de',\n",
       " 'aviones',\n",
       " ',',\n",
       " 'baterías',\n",
       " ',',\n",
       " 'televisores',\n",
       " 'de',\n",
       " 'pantalla',\n",
       " 'plana',\n",
       " ',',\n",
       " 'dispositivos',\n",
       " 'médicos',\n",
       " ',',\n",
       " 'satélites',\n",
       " 'y',\n",
       " 'armas',\n",
       " '.',\n",
       " '4',\n",
       " '5',\n",
       " '6']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.regexp_tokenize(wiki_text2, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
